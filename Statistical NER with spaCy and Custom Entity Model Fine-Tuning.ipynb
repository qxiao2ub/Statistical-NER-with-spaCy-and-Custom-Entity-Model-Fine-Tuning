{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fb1320",
   "metadata": {},
   "source": [
    "\n",
    "# Named Entity Recognition (NER) with spaCy\n",
    "\n",
    "In this notebook I will:\n",
    "1. Use **spaCy's pre-trained statistical NER model** to recognize entities in the news article\n",
    "   `1Text.txt`.\n",
    "2. **Inspect and discuss** the entities recognized by spaCy (persons, organizations, locations, dates, etc.).\n",
    "3. Extend spaCy by **adding a custom entity type** and fine-tuning the NER component on a tiny\n",
    "   annotated dataset, then test the updated model on the original text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eaab6d0-c692-4efa-9e9e-d2a5f37948e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.9-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.15-cp313-cp313-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.13-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.11-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.9-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in e:\\anaconda3\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in e:\\anaconda3\\lib\\site-packages (from spacy) (2.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in e:\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\anaconda3\\lib\\site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in e:\\anaconda3\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda3\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\anaconda3\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in e:\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in e:\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.2-cp313-cp313-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in e:\\anaconda3\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in e:\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.9-cp313-cp313-win_amd64.whl (14.2 MB)\n",
      "   ---------------------------------------- 0.0/14.2 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 8.1/14.2 MB 41.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.2/14.2 MB 38.5 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.13-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading murmurhash-1.0.15-cp313-cp313-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.11-cp313-cp313-win_amd64.whl (117 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "   ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 630.6/630.6 kB 23.8 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.9-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 32.4 MB/s eta 0:00:00\n",
      "Downloading blis-1.3.2-cp313-cp313-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.3-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, cymem, cloudpathlib, catalogue, blis, typer-slim, srsly, preshed, confection, weasel, thinc, spacy\n",
      "\n",
      "   ----------------------------------------  0/16 [wasabi]\n",
      "   ----------------------------------------  0/16 [wasabi]\n",
      "   -- -------------------------------------  1/16 [spacy-loggers]\n",
      "   -- -------------------------------------  1/16 [spacy-loggers]\n",
      "   ----- ----------------------------------  2/16 [spacy-legacy]\n",
      "   ----- ----------------------------------  2/16 [spacy-legacy]\n",
      "   ----- ----------------------------------  2/16 [spacy-legacy]\n",
      "   ------- --------------------------------  3/16 [smart-open]\n",
      "   ------- --------------------------------  3/16 [smart-open]\n",
      "   ------- --------------------------------  3/16 [smart-open]\n",
      "   ---------- -----------------------------  4/16 [murmurhash]\n",
      "   --------------- ------------------------  6/16 [cloudpathlib]\n",
      "   --------------- ------------------------  6/16 [cloudpathlib]\n",
      "   --------------- ------------------------  6/16 [cloudpathlib]\n",
      "   --------------- ------------------------  6/16 [cloudpathlib]\n",
      "   --------------- ------------------------  6/16 [cloudpathlib]\n",
      "   ----------------- ----------------------  7/16 [catalogue]\n",
      "   -------------------- -------------------  8/16 [blis]\n",
      "   -------------------- -------------------  8/16 [blis]\n",
      "   ---------------------- -----------------  9/16 [typer-slim]\n",
      "   ---------------------- -----------------  9/16 [typer-slim]\n",
      "   ---------------------- -----------------  9/16 [typer-slim]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   ------------------------- -------------- 10/16 [srsly]\n",
      "   --------------------------- ------------ 11/16 [preshed]\n",
      "   ------------------------------ --------- 12/16 [confection]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   -------------------------------- ------- 13/16 [weasel]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ----------------------------------- ---- 14/16 [thinc]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ------------------------------------- -- 15/16 [spacy]\n",
      "   ---------------------------------------- 16/16 [spacy]\n",
      "\n",
      "Successfully installed blis-1.3.2 catalogue-2.0.10 cloudpathlib-0.23.0 confection-0.1.5 cymem-2.0.13 murmurhash-1.0.15 preshed-3.0.11 smart-open-7.5.0 spacy-3.8.9 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.9 typer-slim-0.20.0 wasabi-1.1.3 weasel-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d95e7be-c59c-4737-b463-fb5f70e12681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 40.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 37.6 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97118ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Text preview (first 800 characters) ===\n",
      "Sen. Tim Kaine defends Schumer, says House Democrats 'should focus on their own leadership'\n",
      "In an exclusive interview on \"Meet the Press,\" the Virginia senator defended his decision to side with Republicans on a funding bill to reopen the government.\n",
      "Volume Muted Icon\n",
      "Tim Kaine tells House Democrats calling for Schumer’s ouster to ‘focus on their own leadership’\n",
      "02:23\n",
      "Get more news\n",
      "on\n",
      "\n",
      "\n",
      "Savewith a NBCUniversal Profile\n",
      "Create your free profile or log in to save this article\n",
      "Nov. 16, 2025, 10:17 AM EST\n",
      "By Megan Lebowitz\n",
      "WASHINGTON — Sen. Tim Kaine, D-Va., defended Senate Minority Leader Chuck Schumer in an exclusive interview on NBC News’ “Meet the Press,” urging House Democrats to stick to their chamber rather than focus on the party’s Senate leadership.\n",
      "\n",
      "“I don’t tell Ro Khanna or AOC or a\n"
     ]
    }
   ],
   "source": [
    "# If spaCy is not installed, uncomment and run:\n",
    "# !pip install -U spacy\n",
    "\n",
    "# If the English model is not installed, uncomment and run:\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "# Load spaCy's small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the same text file as in Problem 1\n",
    "text_path = Path(\"Problem1Text.txt\")\n",
    "assert text_path.exists(), \"Problem1Text.txt not found in the current directory.\"\n",
    "\n",
    "raw_text = text_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "print(\"=== Text preview (first 800 characters) ===\")\n",
    "print(raw_text[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a829e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entities found: 118\n",
      "\n",
      "Tim Kaine                           -> PERSON\n",
      "Schumer                             -> PERSON\n",
      "House                               -> ORG\n",
      "Democrats                           -> NORP\n",
      "Meet the Press                      -> WORK_OF_ART\n",
      "Virginia                            -> GPE\n",
      "Republicans                         -> NORP\n",
      "Tim Kaine                           -> PERSON\n",
      "House                               -> ORG\n",
      "Democrats                           -> NORP\n",
      "Schumer                             -> PERSON\n",
      "Nov. 16, 2025                       -> DATE\n",
      "10:17 AM EST                        -> TIME\n",
      "Megan Lebowitz                      -> PERSON\n",
      "WASHINGTON                          -> GPE\n",
      "Tim Kaine                           -> PERSON\n",
      "Senate                              -> ORG\n",
      "Chuck Schumer                       -> PERSON\n",
      "NBC News                            -> ORG\n",
      "Meet the Press                      -> WORK_OF_ART\n",
      "House                               -> ORG\n",
      "Democrats                           -> NORP\n",
      "Senate                              -> ORG\n",
      "Ro Khanna                           -> PERSON\n",
      "AOC                                 -> ORG\n",
      "House                               -> ORG\n",
      "Kaine                               -> PERSON\n",
      "Sunday                              -> DATE\n",
      "Ro Khanna                           -> PERSON\n",
      "California                          -> GPE\n",
      "Alexandria Ocasio-Cortez            -> PERSON\n",
      "New York                            -> GPE\n",
      "Alexandra Ocasio-Cortez             -> PERSON\n",
      "Alexandria Ocasio-Cortez            -> PERSON\n",
      "Denver                              -> GPE\n",
      "March 21.Chet                       -> DATE\n",
      "Strange / Getty Images              -> ORG\n",
      "House                               -> ORG\n",
      "Kaine                               -> PERSON\n",
      "Iran                                -> GPE\n",
      "\n",
      "Unique entity labels in this document: ['CARDINAL', 'DATE', 'GPE', 'LAW', 'NORP', 'ORG', 'PERSON', 'TIME', 'WORK_OF_ART']\n"
     ]
    }
   ],
   "source": [
    "# Process full document with spaCy\n",
    "doc = nlp(raw_text)\n",
    "\n",
    "# Collect entities as (text, label_) pairs\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "print(f\"Total entities found: {len(entities)}\\n\")\n",
    "\n",
    "# Show a sample of entities\n",
    "for ent_text, ent_label in entities[:40]:\n",
    "    print(f\"{ent_text:35s} -> {ent_label}\")\n",
    "\n",
    "# Also show unique labels that appear\n",
    "unique_labels = sorted(set(label for _, label in entities))\n",
    "print(\"\\nUnique entity labels in this document:\", unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e885a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## Discussion of spaCy's Pre-Trained NER Results\n",
    "\n",
    "Now see a list of entities and their labels (for example: `PERSON`, `ORG`, `GPE`, `DATE`, etc.).  \n",
    "When interpreting the output, consider the following points and jot down notes in your report:\n",
    "\n",
    "- **Accuracy and precision**\n",
    "  - Which entities are recognized correctly (e.g., *Tim Kaine* → `PERSON`, *WASHINGTON* → `GPE`)?\n",
    "  - Are dates, organizations (e.g., news outlets, parties), and locations identified reliably?\n",
    "\n",
    "- **Coverage / recall**\n",
    "  - Are there important entities that spaCy **misses entirely**?\n",
    "  - Does spaCy merge multi-word names correctly (e.g., *Alexandria Ocasio-Cortez*)?\n",
    "\n",
    "- **Label granularity**\n",
    "  - spaCy's built-in labels are generic (`ORG`, `GPE`, `NORP`, etc.).  \n",
    "    Are there domain-specific distinctions you might want (e.g., `TV_SHOW`, `PROGRAM`, `LAW`)?\n",
    "\n",
    "- **Potential improvements**\n",
    "  - Using a larger model (e.g., `en_core_web_trf`), domain-specific fine-tuning,\n",
    "    or combining statistical NER with rule-based post-processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455d1fb",
   "metadata": {},
   "source": [
    "\n",
    "## Extending NER with a Custom Entity Type\n",
    "\n",
    "Next, I will extend spaCy's NER model with a **custom label**.\n",
    "\n",
    "For this example we introduce the label **`PROGRAM`** to mark *government programs or laws* mentioned\n",
    "in the article, such as:\n",
    "\n",
    "- **\"Affordable Care Act\"**  \n",
    "- **\"Obamacare\"**  \n",
    "- **\"Supplemental Nutrition Assistance Program\"** (SNAP)\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Define a tiny training dataset (`TRAIN_DATA`) with text and character-offset annotations.\n",
    "2. Add the new label to spaCy's NER component.\n",
    "3. Run a short fine-tuning loop on the small annotated dataset.\n",
    "4. Re-run NER on the original text and check whether the model can now recognize `PROGRAM` entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d03a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA examples:\n",
      "The Affordable Care Act subsidies are central to the debate.\n",
      "{'entities': [(4, 23, 'PROGRAM')]}\n",
      "\n",
      "Extending Obamacare subsidies was a key demand for many Democrats.\n",
      "{'entities': [(10, 19, 'PROGRAM')]}\n",
      "\n",
      "The Supplemental Nutrition Assistance Program provides SNAP benefits.\n",
      "{'entities': [(4, 45, 'PROGRAM')]}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "sent1 = \"The Affordable Care Act subsidies are central to the debate.\"\n",
    "start1 = sent1.index(\"Affordable Care Act\")\n",
    "end1 = start1 + len(\"Affordable Care Act\")\n",
    "TRAIN_DATA.append((sent1, {\"entities\": [(start1, end1, \"PROGRAM\")]}))\n",
    "\n",
    "sent2 = \"Extending Obamacare subsidies was a key demand for many Democrats.\"\n",
    "start2 = sent2.index(\"Obamacare\")\n",
    "end2 = start2 + len(\"Obamacare\")\n",
    "TRAIN_DATA.append((sent2, {\"entities\": [(start2, end2, \"PROGRAM\")]}))\n",
    "\n",
    "sent3 = \"The Supplemental Nutrition Assistance Program provides SNAP benefits.\"\n",
    "start3 = sent3.index(\"Supplemental Nutrition Assistance Program\")\n",
    "end3 = start3 + len(\"Supplemental Nutrition Assistance Program\")\n",
    "TRAIN_DATA.append((sent3, {\"entities\": [(start3, end3, \"PROGRAM\")]}))\n",
    "\n",
    "print(\"TRAIN_DATA examples:\")\n",
    "for text, ann in TRAIN_DATA:\n",
    "    print(text)\n",
    "    print(ann)\n",
    "    print()\n",
    "\n",
    "# Add the new label to the existing NER component\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(\"PROGRAM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b860787-0f7b-44a7-bd00-b8a9050e46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example\n",
    "from spacy.util import minibatch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f643bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, Losses: {'ner': np.float32(4.2955832)}\n",
      "Iteration 10, Losses: {'ner': np.float32(1.0348586)}\n",
      "Iteration 15, Losses: {'ner': np.float32(0.027100949)}\n",
      "Iteration 20, Losses: {'ner': np.float32(0.00013697025)}\n",
      "Finished fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "# Convert TRAIN_DATA into spaCy Example objects\n",
    "examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in TRAIN_DATA]\n",
    "\n",
    "# Disable other pipeline components during NER training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "n_iters = 20\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(n_iters):\n",
    "        random.shuffle(examples)\n",
    "        losses = {}\n",
    "\n",
    "        # simple minibatching over Example objects\n",
    "        for batch in minibatch(examples, size=2):\n",
    "            nlp.update(\n",
    "                batch,\n",
    "                drop=0.2,\n",
    "                sgd=optimizer,\n",
    "                losses=losses\n",
    "            )\n",
    "\n",
    "        if (itn + 1) % 5 == 0:\n",
    "            print(f\"Iteration {itn+1}, Losses: {losses}\")\n",
    "\n",
    "print(\"Finished fine-tuning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92b0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom PROGRAM entities found in the original text:\n",
      "\n",
      "Affordable Care Act subsidies                      -> PROGRAM\n",
      "Affordable Care Act subsidies                      -> PROGRAM\n",
      "Supplemental Nutrition Assistance Program (SNAP), federal worker protections and a future Senate vote on health care subsidies.\n",
      "\n",
      " -> PROGRAM\n",
      "Obamacare                                          -> PROGRAM\n",
      "Obamacare                                          -> PROGRAM\n",
      "\n",
      "Sample of other entities after fine-tuning:\n",
      "Tim Kaine                           -> PERSON\n",
      "Schumer                             -> PERSON\n",
      "House                               -> ORG\n",
      "Meet the Press                      -> WORK_OF_ART\n",
      "Virginia                            -> GPE\n",
      "Tim Kaine                           -> PERSON\n",
      "House                               -> ORG\n",
      "Schumer                             -> PERSON\n",
      "Nov. 16, 2025                       -> DATE\n",
      "10:17 AM EST                        -> TIME\n",
      "Megan Lebowitz                      -> PERSON\n",
      "Tim Kaine                           -> PERSON\n",
      "Senate                              -> ORG\n",
      "Chuck Schumer                       -> PERSON\n",
      "NBC News                            -> ORG\n",
      "Meet the Press                      -> WORK_OF_ART\n",
      "House                               -> ORG\n",
      "Senate                              -> ORG\n",
      "Ro Khanna                           -> PERSON\n",
      "AOC                                 -> ORG\n",
      "House                               -> ORG\n",
      "Kaine                               -> PERSON\n",
      "Sunday                              -> DATE\n",
      "Ro Khanna                           -> PERSON\n",
      "California                          -> GPE\n",
      "Alexandria Ocasio-Cortez            -> PERSON\n",
      "Alexandra Ocasio-Cortez             -> PERSON\n",
      "Alexandria Ocasio-Cortez            -> PERSON\n",
      "Denver                              -> GPE\n",
      "March 21.Chet                       -> DATE\n"
     ]
    }
   ],
   "source": [
    "# Run the updated model on the original article\n",
    "updated_doc = nlp(raw_text)\n",
    "\n",
    "program_entities = [(ent.text, ent.label_) for ent in updated_doc.ents if ent.label_ == \"PROGRAM\"]\n",
    "\n",
    "print(\"Custom PROGRAM entities found in the original text:\\n\")\n",
    "for text, label in program_entities:\n",
    "    print(f\"{text:50s} -> {label}\")\n",
    "\n",
    "# For comparison, also show a few standard entities after fine-tuning\n",
    "print(\"\\nSample of other entities after fine-tuning:\")\n",
    "for ent in list(updated_doc.ents)[:30]:\n",
    "    print(f\"{ent.text:35s} -> {ent.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d08ad",
   "metadata": {},
   "source": [
    "\n",
    "## Discussion of Custom Entity Training\n",
    "\n",
    "After the short fine-tuning run, the model should start recognizing mentions of\n",
    "**\"Affordable Care Act\"**, **\"Obamacare\"**, and **\"Supplemental Nutrition Assistance Program\"**\n",
    "in the original article as `PROGRAM` entities.\n",
    "\n",
    "Points to discuss in your write-up:\n",
    "\n",
    "- **Effectiveness**\n",
    "  - Does the updated model correctly tag the targeted phrases as `PROGRAM`?\n",
    "  - Does it over-generalize and mislabel unrelated phrases as `PROGRAM`?\n",
    "\n",
    "- **Impact on existing labels**\n",
    "  - Did the performance on standard entities (e.g., `PERSON`, `ORG`, `GPE`, `DATE`)\n",
    "    remain stable, or did some entities get worse?\n",
    "\n",
    "- **Data requirements**\n",
    "  - With only 3 short training examples, the model can learn basic patterns,\n",
    "    but results will be noisy.\n",
    "  - In practice you would collect **dozens or hundreds** of annotated sentences\n",
    "    for the new label before fine-tuning.\n",
    "\n",
    "- **Further improvements**\n",
    "  - Add more diverse training sentences that use the new label in different contexts.\n",
    "  - Use a development set to monitor overfitting.\n",
    "  - Consider combining statistical training with **spaCy's `EntityRuler`** to enforce\n",
    "    high-precision patterns for critical terms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
